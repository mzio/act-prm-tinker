name: "hotpotqa_mc"
is_async: false
dataset_config:
  path: "yapeichang/hotpotqa-filtered"
  cache_dir: "/scr/mzhang/data/hotpotqa"
  split: "validation"

qa_are_generated: false
ambiguous_titles: false
next_obs_feedback: false
num_fewshot_prompts: 2

num_train_samples: 1000
num_val_samples: 64
num_test_samples: 100

max_turns: 20
num_tries: 1
seed: 0
split: "train"
system_prompt: "You are a helpful assistant that can answer questions and call tools."
truncation_message: "Sorry, you have reached the maximum number of steps. Please try again."
verbose: false

grader_model_config:
  name: "hf_transformer"
  is_async: false
  model_config:
    pretrained_model_name_or_path: "Qwen/Qwen3-8B"
    cache_dir: "/scr/mzhang/models"
    device_map: "auto"
    low_cpu_mem_usage: true
    dtype: "bfloat16"
    # Override chat template (include {% generation %} keyword)
    chat_template_path: "/scr/mzhang/projects/act-prm-tinker/chat_templates/qwen3_8b.jinja"
grader_model_samples: 1
grader_model_verbose: true
